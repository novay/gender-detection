{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624241, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Dataset\n",
    "df = pd.read_csv(\"./data/contoh.csv\", encoding = 'utf-8-sig')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624241, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mengecek apakah ada data yang berisi null\n",
    "df.isnull().values.any()\n",
    "\n",
    "# mengecek jumlah baris data yang berisi null\n",
    "len(df[pd.isnull(df).any(axis=1)])\n",
    "\n",
    "# menghapus baris null dan recheck kembali\n",
    "df = df.dropna(how='all')\n",
    "len(df[pd.isnull(df).any(axis=1)])\n",
    "\n",
    "# mengecek dimensi dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a'adila yasmin humairah</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a'aliyah ananda rusdi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a'am</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a'an darmawan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a'an dwi handika ramadhan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  gender\n",
       "0    a'adila yasmin humairah       0\n",
       "1      a'aliyah ananda rusdi       0\n",
       "2                       a'am       0\n",
       "3              a'an darmawan       1\n",
       "4  a'an dwi handika ramadhan       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mengubah isi kolom jenis kelamin dari text menjadi integer (m = 1; p= 0)\n",
    "map = {\"m\" : 1, \"f\" : 0}\n",
    "df[\"gender\"] = df[\"gender\"].map(map)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Pria:  322538 (51.67%)\n",
      "Jumlah Wanita: 301703 (48.33%)\n"
     ]
    }
   ],
   "source": [
    "# Mengecek distribusi jenis kelamin pada dataset\n",
    "num_obs = len(df)\n",
    "num_true = len(df.loc[df['gender'] == 1])\n",
    "num_false = len(df.loc[df['gender'] == 0])\n",
    "print(\"Jumlah Pria:  {0} ({1:2.2f}%)\".format(num_true, (num_true/num_obs) * 100))\n",
    "print(\"Jumlah Wanita: {0} ({1:2.2f}%)\".format(num_false, (num_false/num_obs) * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Dataset\n",
    "Dataset yang adalah akan dipecah menjadi dua bagian, 70% data akan digunakan sebagai data training untuk melatih mesin. Kemudian 30% sisanya akan digunakan sebagai data testing untuk mengevaluasi akurasi predisksi machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Asli Pria       : 322538 (51.67%)\n",
      "Dataset Asli Wanita     : 301703 (48.33%)\n",
      "\n",
      "Dataset Training Pria   : 225776 (51.67%)\n",
      "Dataset Training Wanita : 211192 (48.33%)\n",
      "\n",
      "Dataset Test Pria       : 96762 (51.67%)\n",
      "Dataset Test Wanita     : 90511 (48.33%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_col_names = [\"name\"]\n",
    "predicted_class_names = [\"gender\"]\n",
    "\n",
    "X = df[feature_col_names].values     \n",
    "y = df[predicted_class_names].values\n",
    "split_test_size = 0.30\n",
    "\n",
    "text_train, text_test, y_train, y_test = train_test_split(X, y, test_size=split_test_size, stratify=y, random_state=42) \n",
    "\n",
    "print(\"Dataset Asli Pria       : {0} ({1:0.2f}%)\".format(len(df.loc[df['gender'] == 1]), (len(df.loc[df['gender'] == 1])/len(df.index)) * 100.0))\n",
    "print(\"Dataset Asli Wanita     : {0} ({1:0.2f}%)\".format(len(df.loc[df['gender'] == 0]), (len(df.loc[df['gender'] == 0])/len(df.index)) * 100.0))\n",
    "print(\"\")\n",
    "print(\"Dataset Training Pria   : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 1]), (len(y_train[y_train[:] == 1])/len(y_train) * 100.0)))\n",
    "print(\"Dataset Training Wanita : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 0]), (len(y_train[y_train[:] == 0])/len(y_train) * 100.0)))\n",
    "print(\"\")\n",
    "print(\"Dataset Test Pria       : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 1]), (len(y_test[y_test[:] == 1])/len(y_test) * 100.0)))\n",
    "print(\"Dataset Test Wanita     : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 0]), (len(y_test[y_test[:] == 0])/len(y_test) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan data uji ke dalam file pickle\n",
    "with open('./models/gender-uji-data.pkl', 'wb') as file:\n",
    "    pickle.dump(text_test, file)\n",
    "\n",
    "# Menyimpan label sebenarnya dari data uji ke dalam file pickle\n",
    "with open('./models/gender-uji-label.pkl', 'wb') as file:\n",
    "    pickle.dump(y_test, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terlihat hasilnya, dataset yang telah dipecah dua tetap dapat mempertahankan persentase distribusi jenis kelamin seperti pada dataset asli."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Extraction\n",
    "Proses features extraction, berpengaruh terhadap hasil akurasi yang didapatkan nantinya. Disini saya kan menggunakan metode simple yaitu CountVectorizer yang akan membuat matrix frekwensi kemunculan dari suatu karakter di tiap nama yang diberikan, dengan opsi analisa ngram_range 2 - 6 hanya di dalam satu kata saja. Misal Muhammad Irfani Sahnur, menghasilkan n-gram :\n",
    "- mu\n",
    "- ham\n",
    "- mad\n",
    "- nur\n",
    "- dst"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2,6))\n",
    "vectorizer.fit(text_train.ravel())\n",
    "\n",
    "with open('./models/vectorizer/vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "X_train = vectorizer.transform(text_train.ravel())\n",
    "X_test = vectorizer.transform(text_test.ravel())\n",
    "\n",
    "with open('./models/vectorizer/X_train.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train, f)\n",
    "\n",
    "with open('./models/vectorizer/X_test.pkl', 'wb') as f:\n",
    "    pickle.dump(X_test, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer(analyzer='char_wb', ngram_range=(2,6))\n",
    "vectorizer_tfidf.fit(text_train.ravel())\n",
    "\n",
    "with open('./models/vectorizer/vectorizer_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer_tfidf, f)\n",
    "\n",
    "X_train_tfidf = vectorizer_tfidf.transform(text_train.ravel())\n",
    "X_test_tfidf = vectorizer_tfidf.transform(text_test.ravel())\n",
    "\n",
    "with open('./models/vectorizer/X_train_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_tfidf, f)\n",
    "\n",
    "with open('./models/vectorizer/X_test_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(X_test_tfidf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./models/vectorizer/vectorizer.pkl', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "    \n",
    "with open('./models/vectorizer/X_train.pkl', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "with open('./models/vectorizer/X_test.pkl', 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "    \n",
    "with open('./models/vectorizer/vectorizer_tfidf.pkl', 'rb') as f:\n",
    "    vectorizer_tfidf = pickle.load(f)\n",
    "    \n",
    "with open('./models/vectorizer/X_train_tfidf.pkl', 'rb') as f:\n",
    "    X_train_tfidf = pickle.load(f)\n",
    "\n",
    "with open('./models/vectorizer/X_test_tfidf.pkl', 'rb') as f:\n",
    "    X_test_tfidf = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Random Forest**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Decision Trees**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.1 Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89038  7724]\n",
      " [ 7346 83165]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.92378   0.92018   0.92198     96762\n",
      "           0    0.91502   0.91884   0.91692     90511\n",
      "\n",
      "    accuracy                        0.91953    187273\n",
      "   macro avg    0.91940   0.91951   0.91945    187273\n",
      "weighted avg    0.91955   0.91953   0.91953    187273\n",
      "\n",
      "CPU times: user 9min 28s, sys: 3.23 s, total: 9min 31s\n",
      "Wall time: 9min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dt =  DecisionTreeClassifier().fit(X_train, y_train.ravel())\n",
    "with open('./models/dt-cv-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_dt, f)\n",
    "\n",
    "dt_pred = clf_dt.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, dt_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, dt_pred, digits=5, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88721  8041]\n",
      " [ 7911 82600]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.91813   0.91690   0.91752     96762\n",
      "           0    0.91129   0.91260   0.91194     90511\n",
      "\n",
      "    accuracy                        0.91482    187273\n",
      "   macro avg    0.91471   0.91475   0.91473    187273\n",
      "weighted avg    0.91482   0.91482   0.91482    187273\n",
      "\n",
      "CPU times: user 25min 51s, sys: 7.35 s, total: 25min 58s\n",
      "Wall time: 14min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dt_tfidf =  DecisionTreeClassifier().fit(X_train_tfidf, y_train.ravel())\n",
    "with open('./models/dt-tfidf-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_dt_tfidf, f)\n",
    "\n",
    "dt_pred_tfidf = clf_dt_tfidf.predict(X_test_tfidf)\n",
    "print(metrics.confusion_matrix(y_test, dt_pred_tfidf, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, dt_pred_tfidf, digits=5, labels=[1,0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.2 Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93045  3717]\n",
      " [ 5086 85425]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.94817   0.96159   0.95483     96762\n",
      "           0    0.95830   0.94381   0.95100     90511\n",
      "\n",
      "    accuracy                        0.95299    187273\n",
      "   macro avg    0.95324   0.95270   0.95292    187273\n",
      "weighted avg    0.95307   0.95299   0.95298    187273\n",
      "\n",
      "CPU times: user 3h 22min 44s, sys: 47.5 s, total: 3h 23min 31s\n",
      "Wall time: 22min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf =  RandomForestClassifier(n_estimators=90, n_jobs=-1).fit(X_train, y_train.ravel())\n",
    "with open('./models/rf-cv-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_rf, f)\n",
    "\n",
    "rf_pred = clf_rf.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, rf_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, rf_pred, digits=5, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92967  3795]\n",
      " [ 5064 85447]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.94834   0.96078   0.95452     96762\n",
      "           0    0.95748   0.94405   0.95072     90511\n",
      "\n",
      "    accuracy                        0.95269    187273\n",
      "   macro avg    0.95291   0.95242   0.95262    187273\n",
      "weighted avg    0.95276   0.95269   0.95268    187273\n",
      "\n",
      "CPU times: user 2h 51min 31s, sys: 50.4 s, total: 2h 52min 21s\n",
      "Wall time: 20min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf_tfidf =  RandomForestClassifier(n_estimators=90, n_jobs=-1).fit(X_train_tfidf, y_train.ravel())\n",
    "with open('./models/rf-tfidf-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_rf_tfidf, f)\n",
    "\n",
    "rf_pred_tfidf = clf_rf_tfidf.predict(X_test_tfidf)\n",
    "print(metrics.confusion_matrix(y_test, rf_pred_tfidf, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, rf_pred_tfidf, digits=5, labels=[1,0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.3 Extra Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93113  3649]\n",
      " [ 5055 85456]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.94851   0.96229   0.95535     96762\n",
      "           0    0.95905   0.94415   0.95154     90511\n",
      "\n",
      "    accuracy                        0.95352    187273\n",
      "   macro avg    0.95378   0.95322   0.95344    187273\n",
      "weighted avg    0.95360   0.95352   0.95351    187273\n",
      "\n",
      "CPU times: user 4h 38min 34s, sys: 1min 48s, total: 4h 40min 22s\n",
      "Wall time: 4h 41min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf_et =  ExtraTreesClassifier().fit(X_train, y_train.ravel())\n",
    "with open('./models/et-cv-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_et, f)\n",
    "\n",
    "et_pred = clf_et.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, et_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, et_pred, digits=5, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93235  3527]\n",
      " [ 4874 85637]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.95032   0.96355   0.95689     96762\n",
      "           0    0.96044   0.94615   0.95324     90511\n",
      "\n",
      "    accuracy                        0.95514    187273\n",
      "   macro avg    0.95538   0.95485   0.95507    187273\n",
      "weighted avg    0.95521   0.95514   0.95513    187273\n",
      "\n",
      "CPU times: user 4h 49min 38s, sys: 2min 18s, total: 4h 51min 56s\n",
      "Wall time: 4h 53min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf_et_tfidf =  ExtraTreesClassifier().fit(X_train_tfidf, y_train.ravel())\n",
    "with open('./models/et-tfidf-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_et_tfidf, f)\n",
    "\n",
    "et_pred_tfidf = clf_et_tfidf.predict(X_test_tfidf)\n",
    "print(metrics.confusion_matrix(y_test, et_pred_tfidf, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, et_pred_tfidf, digits=5, labels=[1,0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Boosting Algorithm**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.1 Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87289  9473]\n",
      " [ 9194 81317]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.90471   0.90210   0.90340     96762\n",
      "           0    0.89566   0.89842   0.89704     90511\n",
      "\n",
      "    accuracy                        0.90032    187273\n",
      "   macro avg    0.90018   0.90026   0.90022    187273\n",
      "weighted avg    0.90034   0.90032   0.90033    187273\n",
      "\n",
      "CPU times: user 3min 59s, sys: 3.97 s, total: 4min 3s\n",
      "Wall time: 4min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_gb =  GradientBoostingClassifier().fit(X_train, y_train.ravel())\n",
    "with open('./models/gb-cv-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_gb, f)\n",
    "\n",
    "gb_pred = clf_gb.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, gb_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, gb_pred, digits=5, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87071  9691]\n",
      " [ 9098 81413]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.90540   0.89985   0.90261     96762\n",
      "           0    0.89363   0.89948   0.89654     90511\n",
      "\n",
      "    accuracy                        0.89967    187273\n",
      "   macro avg    0.89951   0.89966   0.89958    187273\n",
      "weighted avg    0.89971   0.89967   0.89968    187273\n",
      "\n",
      "CPU times: user 12min 49s, sys: 5.14 s, total: 12min 54s\n",
      "Wall time: 12min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_gb_tfidf =  GradientBoostingClassifier().fit(X_train_tfidf, y_train.ravel())\n",
    "with open('./models/gb-tfidf-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_gb_tfidf, f)\n",
    "\n",
    "gb_pred_tfidf = clf_gb_tfidf.predict(X_test_tfidf)\n",
    "print(metrics.confusion_matrix(y_test, gb_pred_tfidf, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, gb_pred_tfidf, digits=5, labels=[1,0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### **2.2 LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/novay/python/blob/main/classification/lightgbm_classifier_example.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.3 Ada Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/novay/python/blob/main/classification/adaboosts_classifier_example.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. SVM (Support Vector Machine)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Naive Bayes**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4.1 Multinominal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91362  5400]\n",
      " [ 3676 86835]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.96132   0.94419   0.95268     96762\n",
      "           0    0.94145   0.95939   0.95034     90511\n",
      "\n",
      "    accuracy                        0.95154    187273\n",
      "   macro avg    0.95139   0.95179   0.95151    187273\n",
      "weighted avg    0.95172   0.95154   0.95155    187273\n",
      "\n",
      "CPU times: user 379 ms, sys: 30.1 ms, total: 409 ms\n",
      "Wall time: 408 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf_nbm =  MultinomialNB().fit(X_train, y_train.ravel())\n",
    "with open('./models/nbm-cv-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_nbm, f)\n",
    "\n",
    "nbm_pred = clf_nbm.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, nbm_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, nbm_pred, digits=5, labels=[1,0]))\n",
    "\n",
    "# 0.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92284  4478]\n",
      " [ 4624 85887]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.95228   0.95372   0.95300     96762\n",
      "           0    0.95045   0.94891   0.94968     90511\n",
      "\n",
      "    accuracy                        0.95140    187273\n",
      "   macro avg    0.95137   0.95132   0.95134    187273\n",
      "weighted avg    0.95140   0.95140   0.95140    187273\n",
      "\n",
      "CPU times: user 387 ms, sys: 22.5 ms, total: 410 ms\n",
      "Wall time: 408 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf_nbm =  MultinomialNB().fit(X_train_tfidf, y_train.ravel())\n",
    "with open('./models/nbm-tfidf-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_nbm, f)\n",
    "\n",
    "nbm_pred = clf_nbm.predict(X_test_tfidf)\n",
    "print(metrics.confusion_matrix(y_test, nbm_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, nbm_pred, digits=5, labels=[1,0]))\n",
    "\n",
    "# 0.4s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4.2 Bernoulli**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90857  5905]\n",
      " [ 3365 87146]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.96429   0.93897   0.95146     96762\n",
      "           0    0.93654   0.96282   0.94950     90511\n",
      "\n",
      "    accuracy                        0.95050    187273\n",
      "   macro avg    0.95041   0.95090   0.95048    187273\n",
      "weighted avg    0.95088   0.95050   0.95051    187273\n",
      "\n",
      "CPU times: user 476 ms, sys: 95.6 ms, total: 572 ms\n",
      "Wall time: 585 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf_nbb =  BernoulliNB().fit(X_train, y_train.ravel())\n",
    "with open('./models/nbb-cv-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_nbb, f)\n",
    "\n",
    "nbb_pred = clf_nbb.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, nbb_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, nbb_pred, digits=5, labels=[1,0]))\n",
    "\n",
    "# 0.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90857  5905]\n",
      " [ 3365 87146]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.96429   0.93897   0.95146     96762\n",
      "           0    0.93654   0.96282   0.94950     90511\n",
      "\n",
      "    accuracy                        0.95050    187273\n",
      "   macro avg    0.95041   0.95090   0.95048    187273\n",
      "weighted avg    0.95088   0.95050   0.95051    187273\n",
      "\n",
      "CPU times: user 471 ms, sys: 67.5 ms, total: 539 ms\n",
      "Wall time: 538 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf_nbb =  BernoulliNB().fit(X_train_tfidf, y_train.ravel())\n",
    "with open('./models/nbb-tfidf-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_nbb, f)\n",
    "\n",
    "nbb_pred = clf_nbb.predict(X_test_tfidf)\n",
    "print(metrics.confusion_matrix(y_test, nbb_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, nbb_pred, digits=5, labels=[1,0]))\n",
    "\n",
    "# 0.5s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91206  5556]\n",
      " [ 8848 81663]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.91157   0.94258   0.92681     96762\n",
      "           0    0.93630   0.90224   0.91896     90511\n",
      "\n",
      "    accuracy                        0.92309    187273\n",
      "   macro avg    0.92393   0.92241   0.92289    187273\n",
      "weighted avg    0.92352   0.92309   0.92302    187273\n",
      "\n",
      "CPU times: user 37min 46s, sys: 9min 9s, total: 46min 55s\n",
      "Wall time: 50min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_knn =  KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train.ravel())\n",
    "with open('./models/knn-cv-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_knn, f)\n",
    "\n",
    "knn_pred = clf_knn.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, knn_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, knn_pred, digits=5, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_knn_tfidf =  KNeighborsClassifier(n_neighbors=5).fit(X_train_tfidf, y_train.ravel())\n",
    "with open('./models/knn-tfidf-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_knn_tfidf, f)\n",
    "\n",
    "knn_pred_tfidf = clf_knn_tfidf.predict(X_test_tfidf)\n",
    "print(metrics.confusion_matrix(y_test, knn_pred_tfidf, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, knn_pred_tfidf, digits=5, labels=[1,0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Regression**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **6.1 Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93727  3035]\n",
      " [ 3579 86932]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.96322   0.96863   0.96592     96762\n",
      "           0    0.96627   0.96046   0.96335     90511\n",
      "\n",
      "    accuracy                        0.96468    187273\n",
      "   macro avg    0.96474   0.96455   0.96464    187273\n",
      "weighted avg    0.96469   0.96468   0.96468    187273\n",
      "\n",
      "CPU times: user 49.5 s, sys: 3.41 s, total: 52.9 s\n",
      "Wall time: 50.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lr =  LogisticRegression(max_iter=2000).fit(X_train, y_train.ravel())\n",
    "with open('./models/lr-cv-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_lr, f)\n",
    "\n",
    "lr_pred = clf_lr.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, lr_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, lr_pred, digits=5, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93687  3075]\n",
      " [ 3896 86615]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.96008   0.96822   0.96413     96762\n",
      "           0    0.96572   0.95696   0.96132     90511\n",
      "\n",
      "    accuracy                        0.96278    187273\n",
      "   macro avg    0.96290   0.96259   0.96272    187273\n",
      "weighted avg    0.96280   0.96278   0.96277    187273\n",
      "\n",
      "CPU times: user 18.9 s, sys: 2.87 s, total: 21.8 s\n",
      "Wall time: 19.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lr_tfidf =  LogisticRegression(max_iter=2000).fit(X_train_tfidf, y_train.ravel())\n",
    "with open('./models/lr-tfidf-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_lr_tfidf, f)\n",
    "\n",
    "lr_pred_tfidf = clf_lr_tfidf.predict(X_test_tfidf)\n",
    "print(metrics.confusion_matrix(y_test, lr_pred_tfidf, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, lr_pred_tfidf, digits=5, labels=[1,0]))\n",
    "\n",
    "# 19.7s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### **6.1 Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93158  3604]\n",
      " [ 5253 85258]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.94662   0.96275   0.95462     96762\n",
      "           0    0.95944   0.94196   0.95062     90511\n",
      "\n",
      "    accuracy                        0.95271    187273\n",
      "   macro avg    0.95303   0.95236   0.95262    187273\n",
      "weighted avg    0.95282   0.95271   0.95269    187273\n",
      "\n",
      "CPU times: user 16min 21s, sys: 11min 11s, total: 27min 33s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "clf_ridge =  RidgeClassifier(max_iter=2000).fit(X_train, y_train.ravel())\n",
    "with open('./models/ridge-cv-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_ridge, f)\n",
    "\n",
    "ridge_pred = clf_ridge.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, ridge_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, ridge_pred, digits=5, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93821  2941]\n",
      " [ 4346 86165]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.95573   0.96961   0.96262     96762\n",
      "           0    0.96699   0.95198   0.95943     90511\n",
      "\n",
      "    accuracy                        0.96109    187273\n",
      "   macro avg    0.96136   0.96079   0.96102    187273\n",
      "weighted avg    0.96117   0.96109   0.96108    187273\n",
      "\n",
      "CPU times: user 1min 19s, sys: 51.4 s, total: 2min 10s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "clf_ridge_tfidf =  RidgeClassifier(max_iter=2000).fit(X_train_tfidf, y_train.ravel())\n",
    "with open('./models/ridge-tfidf-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_ridge_tfidf, f)\n",
    "\n",
    "ridge_pred_tfidf = clf_ridge_tfidf.predict(X_test_tfidf)\n",
    "print(metrics.confusion_matrix(y_test, ridge_pred_tfidf, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, ridge_pred_tfidf, digits=5, labels=[1,0]))\n",
    "\n",
    "# "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7. Discriminant Analysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **7.1 Linear Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pickle\n",
    "\n",
    "with open('./models/vectorizer/X_train.pkl', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "clf_lda =  LinearDiscriminantAnalysis(n_components=1).fit(X_train.toarray(), y_train.ravel())\n",
    "with open('./models/lda-cv-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_lda, f)\n",
    "\n",
    "with open('./models/vectorizer/X_test.pkl', 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "    \n",
    "lda_pred = clf_lda.predict(X_test.toarray())\n",
    "print(metrics.confusion_matrix(y_test, lda_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, lda_pred, digits=5, labels=[1,0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **7.2 Quadratic Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "clf_lda =  LinearDiscriminantAnalysis().fit(X_train.toarray(), y_train.ravel())\n",
    "with open('./models/lda-cv-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_lda, f)\n",
    "\n",
    "lda_pred = clf_lda.predict(X_test.toarray())\n",
    "print(metrics.confusion_matrix(y_test, lda_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, lda_pred, digits=5, labels=[1,0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/novay/miniconda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93314  3448]\n",
      " [ 4083 86428]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.95808   0.96437   0.96121     96762\n",
      "           0    0.96164   0.95489   0.95825     90511\n",
      "\n",
      "    accuracy                        0.95979    187273\n",
      "   macro avg    0.95986   0.95963   0.95973    187273\n",
      "weighted avg    0.95980   0.95979   0.95978    187273\n",
      "\n",
      "CPU times: user 8h 9min 14s, sys: 16h 25min 57s, total: 1d 35min 11s\n",
      "Wall time: 6h 20min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_mlp =  MLPClassifier().fit(X_train, y_train.ravel())\n",
    "with open('./models/mlp-cv-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_mlp, f)\n",
    "\n",
    "mlp_pred = clf_mlp.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, mlp_pred, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, mlp_pred, digits=5, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_mlp_tfidf =  MLPClassifier().fit(X_train_tfidf, y_train.ravel())\n",
    "with open('./models/mlp-tfidf-models.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_mlp_tfidf, f)\n",
    "\n",
    "mlp_pred_tfidf = clf_mlp_tfidf.predict(X_test_tfidf)\n",
    "print(metrics.confusion_matrix(y_test, mlp_pred_tfidf, labels=[1, 0]) )\n",
    "print(\"\")\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, mlp_pred_tfidf, digits=5, labels=[1,0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
