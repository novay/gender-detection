{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Comparing the performance of 13 Classifiers based on F1-score**<br/>\n",
    "**Highlights:**\n",
    "1. Correlation analysis using Pearson coefficient for continuous features and Cramer's V for categorical features\n",
    "2. Data visualization using Seaborn FacetGrid plots\n",
    "3. Results for each ML algorithm are presented after performing 5-fold cross validation based on F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "## Set fixed ranom seeds to get reproducible results\n",
    "seed_val = 0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_val)\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "tf.random.set_seed(seed_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Import and Clean Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 624241 entries, 0 to 624240\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   name    624241 non-null  object\n",
      " 1   gender  624241 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/contoh.csv')\n",
    "map = {\"m\" : 1, \"f\" : 0}\n",
    "df[\"gender\"] = df[\"gender\"].map(map)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47058</th>\n",
       "      <td>aji raja hakim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129766</th>\n",
       "      <td>chayra mikayla utomo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303189</th>\n",
       "      <td>lisnawati mustamin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67052</th>\n",
       "      <td>ana supriati</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261776</th>\n",
       "      <td>iwang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  gender\n",
       "47058         aji raja hakim       1\n",
       "129766  chayra mikayla utomo       0\n",
       "303189    lisnawati mustamin       0\n",
       "67052           ana supriati       0\n",
       "261776                 iwang       1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.1. Missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      0\n",
       "gender    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has no missing values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.2. Type casting from `object` to `Categorical` and deleting features**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding categorical features and converting their pandas dtype to `categorical` will ease visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_categoricals(df, show_levels=False):\n",
    "    \"\"\"\n",
    "        Display uniqueness in each column\n",
    "    \"\"\"\n",
    "    data = [[df[c].unique(), len(df[c].unique()), df[c].isnull().sum()] for c in df.columns]\n",
    "    df_temp = pd.DataFrame(data, index=df.columns,\n",
    "                           columns=['Levels', 'No. of Levels',\n",
    "                                    'No. of Missing Values'])\n",
    "    return df_temp.iloc[:, 0 if show_levels else 1:]\n",
    "\n",
    "\n",
    "def return_categoricals(df, threshold=5):\n",
    "    \"\"\"\n",
    "        Returns a list of columns that have less than or equal to\n",
    "        `threshold` number of unique categorical levels\n",
    "    \"\"\"\n",
    "    return list(filter(lambda c: c if len(df[c].unique()) <= threshold else None,\n",
    "                       df.columns))\n",
    "\n",
    "\n",
    "def to_categorical(columns, df):\n",
    "    \"\"\"\n",
    "        Converts the columns passed in `columns` to categorical datatype\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Levels</th>\n",
       "      <th>No. of Levels</th>\n",
       "      <th>No. of Missing Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>[a'adila yasmin humairah, a'aliyah ananda rusd...</td>\n",
       "      <td>621535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Levels  No. of Levels   \n",
       "name    [a'adila yasmin humairah, a'aliyah ananda rusd...         621535  \\\n",
       "gender                                             [0, 1]              2   \n",
       "\n",
       "        No. of Missing Values  \n",
       "name                        0  \n",
       "gender                      0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_categoricals(df, show_levels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 624241 entries, 0 to 624240\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype   \n",
      "---  ------  --------------   -----   \n",
      " 0   name    624241 non-null  object  \n",
      " 1   gender  624241 non-null  category\n",
      "dtypes: category(1), object(1)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "to_cast = return_categoricals(df, threshold=5)\n",
    "df = to_categorical(to_cast, df)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               a'adila yasmin humairah\n",
       "1                 a'aliyah ananda rusdi\n",
       "2                                  a'am\n",
       "3                         a'an darmawan\n",
       "4             a'an dwi handika ramadhan\n",
       "                      ...              \n",
       "624236                  zysheila rizqia\n",
       "624237                     zyva izabell\n",
       "624238             zyva zhafira mandanu\n",
       "624239    zyvanya dayang putri az-zahra\n",
       "624240                zyvha eleora finn\n",
       "Name: name, Length: 624241, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Correlations in the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>624241</td>\n",
       "      <td>621535</td>\n",
       "      <td>fitri jaya</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>624241</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>322538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  unique         top    freq\n",
       "name    624241  621535  fitri jaya       3\n",
       "gender  624241       2           1  322538"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.1. Correlation between Quantitative variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# sns.heatmap(data=df.astype({'gender': 'int64'}).corr(),\n",
    "#             annot=True, cmap='coolwarm', cbar_kws={'aspect': 50},\n",
    "#             square=True, ax=ax)\n",
    "# plt.xticks(rotation=30, ha='right');\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.2. Correlation between Qualitative/ Categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10, 5))\n",
    "titles = list(df.select_dtypes(include='category'))\n",
    "\n",
    "ax_title_pairs = zip(axs.flat, titles)\n",
    "\n",
    "for ax, title in ax_title_pairs:\n",
    "    sns.countplot(x=title, data=df, palette='Pastel2', ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Data Visualization**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1. Frequency distribution: Categorical Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(by='gender')\n",
    "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(15, 8))\n",
    "titles = list(df.select_dtypes(exclude='category'))\n",
    "\n",
    "ax_title_pairs = zip(axs.flat, titles)\n",
    "\n",
    "for ax, title in ax_title_pairs:\n",
    "    sns.distplot(df_grouped.get_group(0)[title], bins=10, ax=ax, label='No')\n",
    "    sns.distplot(df_grouped.get_group(1)[title], bins=10, ax=ax, label='Yes')\n",
    "    ax.legend(title='DEATH_EVENT')\n",
    "\n",
    "axs.flat[-1].remove()\n",
    "axs.flat[-2].remove()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.2. Frequency distribution: Continuous Variables**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.3. Box plots : Outlier detection**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.4. Heart failure among gender based on smoking and BP**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.5. Heart failure among gender based on anaemia and diabetes**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Data Preprocessing**<br/>\n",
    "Data needs to be one-hot-encoded before applying machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, :-1]\n",
    "y = df['gender']\n",
    "\n",
    "categorical_columns = list(x.select_dtypes(include='category').columns)\n",
    "numeric_columns = list(x.select_dtypes(exclude='category').columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4.1. Train-Test split**<br/>\n",
    "CatBoost classifier does not require any knd of preprocessing while Naive bayes requires a different kind of preprocesing. Therefore, we will use raw/unmodified data (`x_train_cat`, `x_test_cat`, `y_train_cat`, `y_test_cat`) for CatBoost and preprocessed data (`x_train`, `x_test`, `y_train`, `y_test`) for all other classifiers. For Naive Bayes, we will use the raw data (`x_train_cat`, `x_test_cat`, `y_train_cat`, `y_test_cat`) and preprocess it as required in the Naive Bayes section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_splits = train_test_split(x, y, test_size=0.25, random_state=seed_val, shuffle=True, stratify=y)\n",
    "x_train, x_test, y_train, y_test = data_splits\n",
    "\n",
    "\n",
    "# For CatBoost and Naive Bayes\n",
    "data_splits = train_test_split(x, y, test_size=0.25, random_state=seed_val, shuffle=True, stratify=y)\n",
    "x_train_cat, x_test_cat, y_train_cat, y_test_cat = data_splits\n",
    "\n",
    "\n",
    "# list(map(lambda x: x.shape, [x, y, x_train, x_test, y_train, y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "1    80635\n",
       "0    75426\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=y_test);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4.2. Preprocessing Pipeline: One-hot Encoding, Standardization**<br/>\n",
    "We need to standardize the continuous or quantitative variables/ features before applying Machine Learning models. This is important because if we don't standardize the features, features with high variance that are orders of magnitude larger that others might dominate the model fitting process and causing the model unable to learn from other features (with lower variance) correctly as expected.\n",
    "There is no need to standardize categorical variables.\n",
    "\n",
    "To know which algorithms require standardization/ feature scaling read this useful (stackoverflow post)[https://stats.stackexchange.com/questions/244507/what-algorithms-need-feature-scaling-beside-from-svm].\n",
    "\n",
    "*Also we need to standardize the data only after performing train-test split because if we standardize before splitting then there is a chance for some information leak from the test set into the train set. We always want the test set to be completely new to the ML models. (Read more)[https://scikit-learn.org/stable/modules/compose.html#columntransformer-for-heterogeneous-data]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_w/v4htfwfd40ggzfmlgw22dk2m0000gn/T/ipykernel_14647/4084208379.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ('onehot', OneHotEncoder(drop='first', dtype=np.int))])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'bennediktus liing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 22\u001b[0m\n\u001b[1;32m     14\u001b[0m preprocessor \u001b[39m=\u001b[39m ColumnTransformer(\n\u001b[1;32m     15\u001b[0m     transformers\u001b[39m=\u001b[39m[\n\u001b[1;32m     16\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mnum\u001b[39m\u001b[39m'\u001b[39m, numeric_transformer, numeric_columns),\n\u001b[1;32m     17\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mcat\u001b[39m\u001b[39m'\u001b[39m, categorical_transformer, categorical_columns)],\n\u001b[1;32m     18\u001b[0m     remainder\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[39m## Applying Column Transformer\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m x_train \u001b[39m=\u001b[39m preprocessor\u001b[39m.\u001b[39;49mfit_transform(x_train)\n\u001b[1;32m     23\u001b[0m x_test \u001b[39m=\u001b[39m preprocessor\u001b[39m.\u001b[39mtransform(x_test)\n\u001b[1;32m     26\u001b[0m \u001b[39m## Label encoding\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:727\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[1;32m    725\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m--> 727\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(X, y, _fit_transform_one)\n\u001b[1;32m    729\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n\u001b[1;32m    730\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:658\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    652\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m    653\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[1;32m    654\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    655\u001b[0m     )\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    657\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 658\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    659\u001b[0m         delayed(func)(\n\u001b[1;32m    660\u001b[0m             transformer\u001b[39m=\u001b[39;49mclone(trans) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fitted \u001b[39melse\u001b[39;49;00m trans,\n\u001b[1;32m    661\u001b[0m             X\u001b[39m=\u001b[39;49m_safe_indexing(X, column, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[1;32m    662\u001b[0m             y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    663\u001b[0m             weight\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m    664\u001b[0m             message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mColumnTransformer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    665\u001b[0m             message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(name, idx, \u001b[39mlen\u001b[39;49m(transformers)),\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m         \u001b[39mfor\u001b[39;49;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(transformers, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    668\u001b[0m     )\n\u001b[1;32m    669\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    670\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/pipeline.py:445\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    443\u001b[0m fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(last_step, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 445\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39;49mfit_transform(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    446\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\u001b[39m.\u001b[39mtransform(Xt)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 824\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:861\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m    860\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 861\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    862\u001b[0m     X,\n\u001b[1;32m    863\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    864\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    865\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    866\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[1;32m    867\u001b[0m )\n\u001b[1;32m    868\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    870\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.10/site-packages/pandas/core/generic.py:1998\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m   1997\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1998\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(values, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m   1999\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2000\u001b[0m         astype_is_view(values\u001b[39m.\u001b[39mdtype, arr\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m   2001\u001b[0m         \u001b[39mand\u001b[39;00m using_copy_on_write()\n\u001b[1;32m   2002\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mis_single_block\n\u001b[1;32m   2003\u001b[0m     ):\n\u001b[1;32m   2004\u001b[0m         \u001b[39m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m         \u001b[39mif\u001b[39;00m astype_is_view(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m astype_is_view(\n\u001b[1;32m   2006\u001b[0m             values\u001b[39m.\u001b[39mdtype, arr\u001b[39m.\u001b[39mdtype\n\u001b[1;32m   2007\u001b[0m         ):\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'bennediktus liing'"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline \n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop='first', dtype=np.int))])\n",
    "\n",
    "## Column Transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "## Applying Column Transformer\n",
    "x_train = preprocessor.fit_transform(x_train)\n",
    "x_test = preprocessor.transform(x_test)\n",
    "\n",
    "\n",
    "## Label encoding\n",
    "y_trans = LabelEncoder()\n",
    "y_train = y_trans.fit_transform(y_train)\n",
    "y_test = y_trans.transform(y_test)\n",
    "\n",
    "\n",
    "## Save feature names after one-hot encoding for feature importances plots\n",
    "feature_names = list(preprocessor.named_transformers_['cat'].named_steps['onehot'] \\\n",
    "                            .get_feature_names(input_features=categorical_columns))\n",
    "feature_names = numeric_columns + feature_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Data Modeling**<br/>\n",
    "Since the dataset is imbalanced we will be using class-weighted/ cost-sensitive learning. In cost-sensitive learning, a weighted cost function is used. Therefore, misclassifying a sample from the minority class will cost the classifiers more than misclassifying a sample from the majority class. In most of the Sklearn classifiers, cost-sensitive learning can be enabled by setting `class_weight='balanced'`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.1. Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, \\\n",
    "                            precision_recall_curve, roc_curve, accuracy_score\n",
    "from sklearn.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_plot(matrix, labels=None):\n",
    "    \"\"\" Display binary confusion matrix as a Seaborn heatmap \"\"\"\n",
    "    \n",
    "    labels = labels if labels else ['Negative (0)', 'Positive (1)']\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    sns.heatmap(data=matrix, cmap='Blues', annot=True, fmt='d',\n",
    "                xticklabels=labels, yticklabels=labels, ax=ax)\n",
    "    ax.set_xlabel('PREDICTED')\n",
    "    ax.set_ylabel('ACTUAL')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    plt.close()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(y_true, y_probs, label, compare=False, ax=None):\n",
    "    \"\"\" Plot Receiver Operating Characteristic (ROC) curve \n",
    "        Set `compare=True` to use this function to compare classifiers. \"\"\"\n",
    "    \n",
    "    fpr, tpr, thresh = roc_curve(y_true, y_probs, drop_intermediate=False)\n",
    "    auc = round(roc_auc_score(y_true, y_probs), 2)\n",
    "    \n",
    "    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n",
    "    label = ' '.join([label, f'({auc})']) if compare else None\n",
    "    sns.lineplot(x=fpr, y=tpr, ax=axis,\n",
    "                 estimator=None, label=label)\n",
    "    \n",
    "    if compare:\n",
    "        axis.legend(title='Classifier (AUC)', loc='lower right')\n",
    "    else:\n",
    "        axis.text(0.72, 0.05, f'AUC = { auc }', fontsize=12,\n",
    "                  bbox=dict(facecolor='green', alpha=0.4, pad=5))\n",
    "            \n",
    "        # Plot No-Info classifier\n",
    "        axis.fill_between(fpr, fpr, tpr, alpha=0.3, edgecolor='g',\n",
    "                          linestyle='--', linewidth=2)\n",
    "        \n",
    "    axis.set_xlim(0, 1)\n",
    "    axis.set_ylim(0, 1)\n",
    "    axis.set_title('ROC Curve')\n",
    "    axis.set_xlabel('False Positive Rate [FPR]\\n(1 - Specificity)')\n",
    "    axis.set_ylabel('True Positive Rate [TPR]\\n(Sensitivity or Recall)')\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return axis if ax else fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_plot(y_true, y_probs, label, compare=False, ax=None):\n",
    "    \"\"\" Plot Precision-Recall curve.\n",
    "        Set `compare=True` to use this function to compare classifiers. \"\"\"\n",
    "    \n",
    "    p, r, thresh = precision_recall_curve(y_true, y_probs)\n",
    "    p, r, thresh = list(p), list(r), list(thresh)\n",
    "    p.pop()\n",
    "    r.pop()\n",
    "    \n",
    "    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n",
    "    \n",
    "    if compare:\n",
    "        sns.lineplot(r, p, estimator=None,\n",
    "                     ax=axis, label=label)\n",
    "        axis.set_xlabel('Recall')\n",
    "        axis.set_ylabel('Precision')\n",
    "        axis.legend(loc='lower left')\n",
    "    else:\n",
    "        sns.lineplot(thresh, p, estimator=None,\n",
    "                     label='Precision', ax=axis)\n",
    "        axis.set_xlabel('Threshold')\n",
    "        axis.set_ylabel('Precision')\n",
    "        axis.legend(loc='lower left')\n",
    "\n",
    "        axis_twin = axis.twinx()\n",
    "        sns.lineplot(thresh, r, estimator=None,\n",
    "                     color='limegreen', label='Recall', ax=axis_twin)\n",
    "        axis_twin.set_ylabel('Recall')\n",
    "        axis_twin.set_ylim(0, 1)\n",
    "        axis_twin.legend(bbox_to_anchor=(0.24, 0.18))\n",
    "    \n",
    "    axis.set_xlim(0, 1)\n",
    "    axis.set_ylim(0, 1)\n",
    "    axis.set_title('Precision Vs Recall')\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return axis if ax else fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_plot(importances, feature_labels, ax=None):\n",
    "    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1, figsize=(5, 10))\n",
    "    sns.barplot(x=importances, y=feature_labels, ax=axis)\n",
    "    axis.set_title('Feature Importance Measures')\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return axis if ax else fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clf(clf, x_train, y_train, sample_weight=None, refit=False):\n",
    "    train_time = 0\n",
    "    \n",
    "    try:\n",
    "        if refit:\n",
    "            raise NotFittedError\n",
    "        y_pred_train = clf.predict(x_train)\n",
    "        \n",
    "        # For neural nets\n",
    "        y_pred_train = np.where(y_pred_train.flatten() > 0.5, 1, 0)\n",
    "        \n",
    "    except NotFittedError:\n",
    "        start = timeit.default_timer()\n",
    "        \n",
    "        if sample_weight is not None:\n",
    "            clf.fit(x_train, y_train, sample_weight=sample_weight)\n",
    "        else:\n",
    "            clf.fit(x_train, y_train)\n",
    "        \n",
    "        end = timeit.default_timer()\n",
    "        train_time = end - start\n",
    "        \n",
    "        y_pred_train = clf.predict(x_train)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    return clf, y_pred_train, train_acc, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_memory_size(clf):\n",
    "    return sys.getsizeof(pickle.dumps(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(clf, x_train, y_train, x_test, y_test, display_scores=[],\n",
    "           sample_weight=None, refit=False, importance_plot=False,\n",
    "           confusion_labels=None, feature_labels=None, neural_net=False,\n",
    "           verbose=True):\n",
    "    \"\"\" Trains the passed classifier if not already trained and reports\n",
    "        various metrics of the trained classifier \"\"\"\n",
    "    \n",
    "    dump = dict()\n",
    "    \n",
    "    ## Train if not already trained\n",
    "    clf, train_predictions, \\\n",
    "    train_acc, train_time = train_clf(clf, x_train, y_train,\n",
    "                                      sample_weight=sample_weight,\n",
    "                                      refit=refit)\n",
    "    ## Testing\n",
    "    start = timeit.default_timer()\n",
    "    test_predictions = clf.predict(x_test)\n",
    "    end = timeit.default_timer()\n",
    "    test_time = end - start\n",
    "    \n",
    "    # For neural nets\n",
    "    if neural_net:\n",
    "        y_probs = np.copy(test_predictions)\n",
    "        test_predictions = np.where(test_predictions.flatten() > 0.5, 1, 0)\n",
    "    else:\n",
    "        y_probs = clf.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "    test_acc = accuracy_score(y_test, test_predictions)\n",
    "    roc_auc = roc_auc_score(y_test, y_probs)\n",
    "        \n",
    "    ## Additional scores\n",
    "    scores_dict = dict()\n",
    "    for func in display_scores:\n",
    "        scores_dict[func.__name__] = [func(y_train, train_predictions),\n",
    "                                      func(y_test, test_predictions)]\n",
    "        \n",
    "    ## Model Memory\n",
    "    model_mem = None\n",
    "    if not neural_net:\n",
    "        model_mem = round(model_memory_size(clf) / 1024, 2)\n",
    "    \n",
    "    print(clf)\n",
    "    print(\"\\n=============================> TRAIN-TEST DETAILS <======================================\")\n",
    "    \n",
    "    ## Metrics\n",
    "    print(f\"Train Size: {x_train.shape[0]} samples\")\n",
    "    print(f\" Test Size: {x_test.shape[0]} samples\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(f\"Training Time: {round(train_time, 3)} seconds\")\n",
    "    print(f\" Testing Time: {round(test_time, 3)} seconds\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"Train Accuracy: \", train_acc)\n",
    "    print(\" Test Accuracy: \", test_acc)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    if display_scores:\n",
    "        for k, v in scores_dict.items():\n",
    "            score_name = ' '.join(map(lambda x: x.title(), k.split('_')))\n",
    "            print(f'Train {score_name}: ', v[0])\n",
    "            print(f' Test {score_name}: ', v[1])\n",
    "            print()\n",
    "        print(\"---------------------------------------------\")\n",
    "    \n",
    "    print(\" Area Under ROC (test): \", roc_auc)\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(f\"Model Memory Size: {model_mem} kB\")\n",
    "    print(\"\\n=============================> CLASSIFICATION REPORT <===================================\")\n",
    "    \n",
    "    ## Classification Report\n",
    "    clf_rep = classification_report(y_test, test_predictions, output_dict=True)\n",
    "    \n",
    "    print(classification_report(y_test, test_predictions,\n",
    "                                target_names=confusion_labels))\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n================================> CONFUSION MATRIX <=====================================\")\n",
    "    \n",
    "        ## Confusion Matrix HeatMap\n",
    "        display(confusion_plot(confusion_matrix(y_test, test_predictions),\n",
    "                               labels=confusion_labels))\n",
    "        print(\"\\n=======================================> PLOTS <=========================================\")\n",
    "\n",
    "\n",
    "        ## Variable importance plot\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 10))\n",
    "        roc_axes = axes[0, 0]\n",
    "        pr_axes = axes[0, 1]\n",
    "        importances = None\n",
    "\n",
    "        if importance_plot:\n",
    "            if not feature_labels:\n",
    "                raise RuntimeError(\"'feature_labels' argument not passed \"\n",
    "                                   \"when 'importance_plot' is True\")\n",
    "\n",
    "            try:\n",
    "                importances = pd.Series(clf.feature_importances_,\n",
    "                                        index=feature_labels) \\\n",
    "                                .sort_values(ascending=False)\n",
    "            except AttributeError:\n",
    "                try:\n",
    "                    importances = pd.Series(clf.coef_.ravel(),\n",
    "                                            index=feature_labels) \\\n",
    "                                    .sort_values(ascending=False)\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "\n",
    "            if importances is not None:\n",
    "                # Modifying grid\n",
    "                grid_spec = axes[0, 0].get_gridspec()\n",
    "                for ax in axes[:, 0]:\n",
    "                    ax.remove()   # remove first column axes\n",
    "                large_axs = fig.add_subplot(grid_spec[0:, 0])\n",
    "\n",
    "                # Plot importance curve\n",
    "                feature_importance_plot(importances=importances.values,\n",
    "                                        feature_labels=importances.index,\n",
    "                                        ax=large_axs)\n",
    "                large_axs.axvline(x=0)\n",
    "\n",
    "                # Axis for ROC and PR curve\n",
    "                roc_axes = axes[0, 1]\n",
    "                pr_axes = axes[1, 1]\n",
    "            else:\n",
    "                # remove second row axes\n",
    "                for ax in axes[1, :]:\n",
    "                    ax.remove()\n",
    "        else:\n",
    "            # remove second row axes\n",
    "            for ax in axes[1, :]:\n",
    "                ax.remove()\n",
    "\n",
    "\n",
    "        ## ROC and Precision-Recall curves\n",
    "        clf_name = clf.__class__.__name__\n",
    "        roc_plot(y_test, y_probs, clf_name, ax=roc_axes)\n",
    "        precision_recall_plot(y_test, y_probs, clf_name, ax=pr_axes)\n",
    "\n",
    "        fig.subplots_adjust(wspace=5)\n",
    "        fig.tight_layout()\n",
    "        display(fig)\n",
    "    \n",
    "    ## Dump to report_dict\n",
    "    dump = dict(clf=clf, accuracy=[train_acc, test_acc], **scores_dict,\n",
    "                train_time=train_time, train_predictions=train_predictions,\n",
    "                test_time=test_time, test_predictions=test_predictions,\n",
    "                test_probs=y_probs, report=clf_rep, roc_auc=roc_auc,\n",
    "                model_memory=model_mem)\n",
    "    \n",
    "    return clf, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(y_test=None, clf_reports=[], labels=[], score='accuracy'):\n",
    "    \"\"\" Compare evaluation metrics for the True Positive class [1] of \n",
    "        binary classifiers passed in the argument and plot ROC and PR curves.\n",
    "        \n",
    "        Arguments:\n",
    "        ---------\n",
    "        y_test: to plot ROC and Precision-Recall curves\n",
    "         score: is the name corresponding to the sklearn metrics\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        compare_table: pandas DataFrame containing evaluated metrics\n",
    "                  fig: `matplotlib` figure object with ROC and PR curves \"\"\"\n",
    "\n",
    "    \n",
    "    ## Classifier Labels\n",
    "    default_names = [rep['clf'].__class__.__name__ for rep in clf_reports]\n",
    "    clf_names =  labels if len(labels) == len(clf_reports) else default_names\n",
    "    \n",
    "    \n",
    "    ## Compare Table\n",
    "    table = dict()\n",
    "    index = ['Train ' + score, 'Test ' + score, 'Overfitting', 'Accuracy', 'ROC Area',\n",
    "             'Precision', 'Recall', 'F1-score', 'Support']\n",
    "    for i in range(len(clf_reports)):\n",
    "        scores = [round(i, 3) for i in clf_reports[i][score]]\n",
    "        \n",
    "        roc_auc = clf_reports[i]['roc_auc']\n",
    "        test_acc = clf_reports[i]['accuracy'][1]\n",
    "        \n",
    "        # Get metrics of True Positive class from sklearn classification_report\n",
    "        true_positive_metrics = list(clf_reports[i]['report'][\"1\"].values())\n",
    "        \n",
    "        table[clf_names[i]] = scores + [scores[1] < scores[0], test_acc, roc_auc] + \\\n",
    "                              true_positive_metrics\n",
    "    \n",
    "    table = pd.DataFrame(data=table, index=index)\n",
    "    \n",
    "    \n",
    "    ## Compare Plots\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "    \n",
    "    # ROC and Precision-Recall\n",
    "    for i in range(len(clf_reports)):\n",
    "        clf_probs = clf_reports[i]['test_probs']\n",
    "        roc_plot(y_test, clf_probs, label=clf_names[i],\n",
    "                 compare=True, ax=axes[0])\n",
    "        precision_recall_plot(y_test, clf_probs, label=clf_names[i],\n",
    "                              compare=True, ax=axes[1])\n",
    "    # Plot No-Info classifier\n",
    "    axes[0].plot([0,1], [0,1], linestyle='--', color='green')\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    plt.close()\n",
    "    \n",
    "    return table.T, fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.2. Naive Bayes**<br/>\n",
    "The fundamental assumption made by Naive Bayes regarding the data is **class conditional independence of features**. Sklearn provides different variants of Naive Bayes depending on whether the features follow a categorical distribution (CategoricalNB), normal distribution (GaussianNB), bernoulli distribution (BernoulliNB), multinomial distribution (MultinomialNB).\n",
    "\n",
    "Since majority of the features are categorical and follow a categorical distribution, we will use CategoricalNB. Continuous features will be discretized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "primary_eval_metric = metrics.f1_score\n",
    "\n",
    "confusion_lbs = ['Perempuan', 'Laki-Laki']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB \n",
    "from sklearn.preprocessing import KBinsDiscretizer, OrdinalEncoder\n",
    "\n",
    "\n",
    "numeric_trans_nb = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('kbn', KBinsDiscretizer(n_bins=5, encode='ordinal'))])\n",
    "\n",
    "categorical_trans_nb = Pipeline(steps=[\n",
    "    ('ordinal', OrdinalEncoder(dtype=np.int64))])\n",
    "\n",
    "## Column Transformer\n",
    "preprocessor_nb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_trans_nb, numeric_columns),\n",
    "        ('cat', categorical_trans_nb, categorical_columns)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "## Applying Column Transformer\n",
    "x_train_nb = preprocessor_nb.fit_transform(x_train_cat)\n",
    "x_test_nb = preprocessor_nb.transform(x_test_cat)\n",
    "\n",
    "nb_clf = CategoricalNB()\n",
    "\n",
    "nb_clf, nb_report = report(nb_clf, x_train_nb, y_train,\n",
    "                           x_test_nb, y_test,\n",
    "                           display_scores=[primary_eval_metric],\n",
    "                           refit=True,\n",
    "                           confusion_labels=confusion_lbs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.3. Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegressionCV\n\u001b[1;32m      3\u001b[0m logit_cv \u001b[39m=\u001b[39m LogisticRegressionCV(class_weight\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                 max_iter\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, penalty\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ml1\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                                 scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m, solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                                 n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, random_state\u001b[39m=\u001b[39mseed_val,\n\u001b[1;32m      7\u001b[0m                                 refit\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m logit_cv, logit_report \u001b[39m=\u001b[39m report(logit_cv, x_train, y_train,\n\u001b[1;32m     10\u001b[0m                                 x_test, y_test,\n\u001b[1;32m     11\u001b[0m                                 display_scores\u001b[39m=\u001b[39m[primary_eval_metric],\n\u001b[1;32m     12\u001b[0m                                 importance_plot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m---> 13\u001b[0m                                 feature_labels\u001b[39m=\u001b[39mfeature_names,\n\u001b[1;32m     14\u001b[0m                                 confusion_labels\u001b[39m=\u001b[39mconfusion_lbs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_names' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "logit_cv = LogisticRegressionCV(class_weight='balanced', cv=5,\n",
    "                                max_iter=500, penalty='l1',\n",
    "                                scoring='f1', solver='liblinear',\n",
    "                                n_jobs=-1, random_state=seed_val,\n",
    "                                refit=True, verbose=0)\n",
    "\n",
    "logit_cv, logit_report = report(logit_cv, x_train, y_train,\n",
    "                                x_test, y_test,\n",
    "                                display_scores=[primary_eval_metric],\n",
    "                                importance_plot=True,\n",
    "                                feature_labels=feature_names,\n",
    "                                confusion_labels=confusion_lbs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.4. K-Nearest Neighbors**<br/>\n",
    "KNN estimator in Scikit-learn does not provide a way to pass class-weights to enable cost-sensitive/ class-weighted learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=3,\n",
    "                           weights='distance', n_jobs=-1)\n",
    "\n",
    "knn, knn_report = report(knn, x_train, y_train,\n",
    "                         x_test, y_test,\n",
    "                         display_scores=[primary_eval_metric],\n",
    "                         importance_plot=True,\n",
    "                         feature_labels=feature_names,\n",
    "                         confusion_labels=confusion_lbs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.5. Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(class_weight='balanced',\n",
    "                                       criterion='entropy',\n",
    "                                       max_depth=6, max_leaf_nodes=10,\n",
    "                                       min_samples_split=0.2,\n",
    "                                       random_state=seed_val)\n",
    "\n",
    "decision_tree, decision_tree_report = report(decision_tree, x_train, y_train,\n",
    "                                             x_test, y_test,\n",
    "                                             display_scores=[primary_eval_metric],\n",
    "                                             importance_plot=True,\n",
    "                                             feature_labels=feature_names,\n",
    "                                             confusion_labels=confusion_lbs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.6. Decision Trees with Bagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging_dtree = DecisionTreeClassifier(max_depth=2, class_weight='balanced',\n",
    "                                       criterion='entropy', random_state=seed_val)\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=bagging_dtree,\n",
    "                                max_samples=0.745, n_estimators=100,\n",
    "                                max_features=0.37,\n",
    "                                n_jobs=-1, random_state=seed_val)\n",
    "\n",
    "bagging_clf, bagging_clf_report = report(bagging_clf, x_train, y_train,\n",
    "                                         x_test, y_test,\n",
    "                                         display_scores=[primary_eval_metric],\n",
    "                                         feature_labels=feature_names,\n",
    "                                         confusion_labels=confusion_lbs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.7. Random Forests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
    "                                       max_depth=2, max_samples=0.63, n_estimators=100,\n",
    "                                       n_jobs=-1, random_state=seed_val)\n",
    "\n",
    "random_forest, random_forest_report = report(random_forest, x_train, y_train,\n",
    "                                             x_test, y_test,\n",
    "                                             display_scores=[primary_eval_metric],\n",
    "                                             importance_plot=True,\n",
    "                                             feature_labels=feature_names,\n",
    "                                             confusion_labels=confusion_lbs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.8. Decision Trees with AdaBoost**<br/>\n",
    "The default base estimator for `AdaBoostClassifier` is `DecisionTreeClassifier(max_depth=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboot = AdaBoostClassifier(n_estimators=57, learning_rate=0.064,\n",
    "                             random_state=seed_val)\n",
    "\n",
    "adaboot, adaboot_report = report(adaboot, x_train, y_train,\n",
    "                                 x_test, y_test,\n",
    "                                 display_scores=[primary_eval_metric],\n",
    "                                 importance_plot=True,\n",
    "                                 feature_labels=feature_names,\n",
    "                                 confusion_labels=confusion_lbs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.9. Linear SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "linear_svc = SVC(C=2.1, kernel='linear', probability=True,\n",
    "                 class_weight='balanced', random_state=seed_val)\n",
    "\n",
    "linear_svc, linear_svc_report = report(linear_svc, x_train, y_train,\n",
    "                                       x_test, y_test,\n",
    "                                       display_scores=[primary_eval_metric],\n",
    "                                       importance_plot=True,\n",
    "                                       feature_labels=feature_names,\n",
    "                                       confusion_labels=confusion_lbs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.10. SVM with RBF kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svc = SVC(C=0.25, kernel='rbf', probability=True,\n",
    "              class_weight='balanced', random_state=seed_val)\n",
    "\n",
    "rbf_svc, rbf_svc_report = report(rbf_svc, x_train, y_train,\n",
    "                                 x_test, y_test,\n",
    "                                 display_scores=[primary_eval_metric],\n",
    "                                 importance_plot=True,\n",
    "                                 feature_labels=feature_names,\n",
    "                                 confusion_labels=confusion_lbs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.11. XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "cls_weight = (y_train.shape[0] - np.sum(y_train)) / np.sum(y_train)\n",
    "\n",
    "params = {'learning_rate': 0.014724527414939945,\n",
    "          'num_boost_round': 3451,\n",
    "          'gamma': 0.4074467665676125,\n",
    "          'reg_lambda': 31.082862686792716,\n",
    "          'reg_alpha': 0.008543705214252668,\n",
    "          'max_depth': 7,\n",
    "          'min_child_weight': 3.2435633342899867e-06,\n",
    "          'subsample': 0.15432895096353877,\n",
    "          'colsample_bytree': 0.7665394913603492}\n",
    "\n",
    "xgb_clf = XGBClassifier(**params, scale_pos_weight=cls_weight,\n",
    "                        random_state=seed_val, n_jobs=-1)\n",
    "xgb_clf.fit(x_train, y_train);\n",
    "\n",
    "xgb_clf, xgb_report = report(xgb_clf, x_train, y_train,\n",
    "                             x_test, y_test,\n",
    "                             display_scores=[primary_eval_metric],\n",
    "                             importance_plot=True,\n",
    "                             feature_labels=feature_names,\n",
    "                             confusion_labels=confusion_lbs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.12. LightGBM**<br/>\n",
    "LightGBM is similar to XGBoost but grows the trees in the ensemble based on Leaf-wise growth algorithm unlike Level-wise algorithm in XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "params = {'objective': 'binary', 'verbose': -1, 'lambda_l1': 0.0,\n",
    "          'lambda_l2': 0.0, 'num_leaves': 31, 'feature_fraction': 0.8,\n",
    "          'bagging_fraction': 0.49916588402130324, 'bagging_freq': 3,\n",
    "          'min_child_samples': 20}\n",
    "\n",
    "lgbm_clf = LGBMClassifier(**params, random_state=seed_val, n_jobs=-1)\n",
    "lgbm_clf.fit(x_train, y_train);\n",
    "\n",
    "lgbm_clf, lgbm_report = report(lgbm_clf, x_train, y_train,\n",
    "                               x_test, y_test,\n",
    "                               display_scores=[primary_eval_metric],\n",
    "                               importance_plot=True,\n",
    "                               feature_labels=feature_names,\n",
    "                               confusion_labels=confusion_lbs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.13. CatBoost**<br/>\n",
    "Cat boost performs better without One-hot encoding because it performs an internal categorical encoding that is similar to Leave One Out Encoding (LOOE). So, we can give the dataframe as input to the catboost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost_clf = CatBoostClassifier(cat_features=categorical_columns,\n",
    "                                  l2_leaf_reg=120, depth=6,\n",
    "                                  auto_class_weights='Balanced',\n",
    "                                  iterations=200, learning_rate=0.16,\n",
    "                                  use_best_model=True,\n",
    "                                  early_stopping_rounds=150,\n",
    "                                  eval_metric='F1', random_state=seed_val)\n",
    "\n",
    "catboost_clf.fit(x_train_cat, y_train, \n",
    "                 eval_set=(x_train_cat, y_train),\n",
    "                 verbose=False)\n",
    "\n",
    "\n",
    "f_labels = categorical_columns+numeric_columns\n",
    "catboost_clf, catboost_report = report(catboost_clf, x_train_cat, y_train,\n",
    "                                       x_test_cat, y_test,\n",
    "                                       display_scores=[primary_eval_metric],\n",
    "                                       importance_plot=True,\n",
    "                                       feature_labels=f_labels,\n",
    "                                       confusion_labels=confusion_lbs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.14. Artificial Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "CLASS_WEIGHT = compute_class_weight(class_weight='balanced',\n",
    "                                    classes=np.unique(y_train),\n",
    "                                    y=y_train)\n",
    "CLASS_WEIGHT = dict(zip([0, 1], CLASS_WEIGHT))\n",
    "\n",
    "BATCHSIZE = x_train.shape[0]\n",
    "FEATURES = x_train.shape[1]\n",
    "CLASSES = 1\n",
    "EPOCHS = 1000\n",
    "N_TRAIN_EXAMPLES = x_train.shape[0]\n",
    "STEPS_PER_EPOCH = N_TRAIN_EXAMPLES // BATCHSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(params, num_classes, metrics):    \n",
    "    layers_list = [keras.layers.InputLayer(input_shape=(FEATURES,))]\n",
    "    \n",
    "    for l in range(1, params['num_layers'] + 1):\n",
    "        new_layers = [keras.layers.BatchNormalization(),\n",
    "                      keras.layers.Dense(params[f'units_{l}'], activation='relu',\n",
    "                                         kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed_val),\n",
    "                                         kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                                         use_bias=True),\n",
    "                      keras.layers.Dropout(params[f'drop_rate_{l}'], seed=seed_val)]\n",
    "        layers_list.extend(new_layers)\n",
    "    \n",
    "    layers_list.append(keras.layers.Dense(num_classes, activation='sigmoid'))\n",
    "    model = keras.Sequential(layers=layers_list)\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "params_dict = {'drop_rate_1': 0.7, 'num_layers': 1, 'units_1': 8}\n",
    "\n",
    "## tf.keras.metrics does not have F1-score so we will use Recall\n",
    "model = create_model(params=params_dict, num_classes=CLASSES,\n",
    "                     metrics=[keras.metrics.Recall()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, verbose=0)]\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train,\n",
    "                    batch_size=BATCHSIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=0,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    shuffle=True,\n",
    "                    class_weight=CLASS_WEIGHT,\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    use_multiprocessing=True)\n",
    "\n",
    "_, nn_report = report(model, x_train, y_train,\n",
    "                      x_test, y_test,\n",
    "                      display_scores=[primary_eval_metric],\n",
    "                      confusion_labels=confusion_lbs,\n",
    "                      neural_net=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Model Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_list = [nb_report, logit_report, knn_report, decision_tree_report,               \n",
    "               bagging_clf_report, random_forest_report, adaboot_report,\n",
    "               xgb_report, lgbm_report, catboost_report, nn_report,\n",
    "               linear_svc_report, rbf_svc_report]\n",
    "clf_labels = [rep['clf'].__class__.__name__ for rep in report_list]\n",
    "clf_labels[-3] = 'Neural Nets'\n",
    "clf_labels[-2] = 'Linear SVC'\n",
    "clf_labels[-1] = 'RBF SVC'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **6.1. Evaluation Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_table, compare_plot = compare_models(y_test, clf_reports=report_list,\n",
    "                                             labels=clf_labels,\n",
    "                                             score=primary_eval_metric.__name__)\n",
    "\n",
    "compare_table.sort_values(by=['Overfitting', 'F1-score'], ascending=[True, False])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **6.2. ROC and PR Curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
